{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rain days\n",
      "0         10\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def num_rainy_days(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - a count of the number of days in the dataframe where\n",
    "    the rain column is equal to 1 (i.e., the number of days it\n",
    "    rained).  The dataframe will be titled 'weather_data'. You'll\n",
    "    need to provide the SQL query.  You might find SQL's count function\n",
    "    useful for this exercise.  You can read more about it here:\n",
    "    \n",
    "    https://dev.mysql.com/doc/refman/5.1/en/counting-rows.html\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select count(rain) as 'Rain Days' \n",
    "    from weather_data\n",
    "    where cast(rain as nteger)=1;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(num_rainy_days('weather-underground.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fog  max temperature\n",
      "0    0               86\n",
      "1    1               81\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def max_temp_aggregate_by_fog(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return two columns and\n",
    "    two rows - whether it was foggy or not (0 or 1) and the max\n",
    "    maxtempi for that fog value (i.e., the maximum max temperature\n",
    "    for both foggy and non-foggy days).  The dataframe will be \n",
    "    titled 'weather_data'. You'll need to provide the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select fog, max(maxtempi) as 'Max Temperature'\n",
    "    from weather_data\n",
    "    group by fog;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(max_temp_aggregate_by_fog('weather-underground.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weekend temperature\n",
      "0            65.111111\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - the average meantempi on days that are a Saturday\n",
    "    or Sunday (i.e., the the average mean temperature on weekends).\n",
    "    The dataframe will be titled 'weather_data' and you can access\n",
    "    the date in the dataframe via the 'date' column.\n",
    "    \n",
    "    You'll need to provide  the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    Also, you can convert dates to days of the week via the 'strftime' keyword in SQL.\n",
    "    For example, cast (strftime('%w', date) as integer) will return 0 if the date\n",
    "    is a Sunday or 6 if the date is a Saturday.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select avg(meantempi) as 'weekend Temperature'\n",
    "    from weather_data\n",
    "    where \n",
    "      cast (strftime('%w', date) as integer) = 0 or cast (strftime('%w', date) as integer) = 6;\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(avg_weekend_temperature('weather-underground.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(mintempi)\n",
      "0          61.25\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def avg_min_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data. More specifically you want to find the average\n",
    "    minimum temperature (mintempi column of the weather dataframe) on \n",
    "    rainy days where the minimum temperature is greater than 55 degrees.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select avg(mintempi)\n",
    "    from weather_data\n",
    "    where cast(rain as interger) = 1 and cast(mintempi as interger) > 55;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(avg_min_temperature('weather-underground.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def fix_turnstile_data(filenames):\n",
    "    '''\n",
    "    Filenames is a list of MTA Subway turnstile text files. A link to an example\n",
    "    MTA Subway turnstile text file can be seen at the URL below:\n",
    "    http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt\n",
    "    \n",
    "    As you can see, there are numerous data points included in each row of the\n",
    "    a MTA Subway turnstile text file. \n",
    "\n",
    "    You want to write a function that will update each row in the text\n",
    "    file so there is only one entry per row. A few examples below:\n",
    "    A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
    "    A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
    "    A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
    "    \n",
    "    Write the updates to a different text file in the format of \"updated_\" + filename.\n",
    "    For example:\n",
    "        1) if you read in a text file called \"turnstile_110521.txt\"\n",
    "        2) you should write the updated data to \"updated_turnstile_110521.txt\"\n",
    "\n",
    "    The order of the fields should be preserved. Remember to read through the \n",
    "    Instructor Notes below for more details on the task. \n",
    "    \n",
    "    In addition, here is a CSV reader/writer introductory tutorial:\n",
    "    http://goo.gl/HBbvyy\n",
    "    \n",
    "    You can see a sample of the turnstile text file that's passed into this function\n",
    "    and the the corresponding updated file by downloading these files from the resources:\n",
    "    \n",
    "    Sample input file: turnstile_110528.txt\n",
    "    Sample updated file: solution_turnstile_110528.txt\n",
    "    '''\n",
    "    for name in filenames:\n",
    "        # your code here\n",
    "        f_in = open(name, 'r')\n",
    "        f_out = open(\"updated_\" + name, 'w')\n",
    "\n",
    "        reader_in = csv.reader(f_in, delimiter=',')\n",
    "        writer_out = csv.writer(f_out, delimiter=',')\n",
    "        \n",
    "        for line in reader_in:\n",
    "            # print(len(line))\n",
    "            for n in range(3, len(line), 5):             \n",
    "                # formating the number and remove space\n",
    "                line[n+3] = int(line[n+3].replace(\" \", \"\"))\n",
    "                line[n+4] = int(line[n+4].replace(\" \", \"\"))\n",
    "                \n",
    "                update_line = [line[0],line[1],line[2],line[n],line[n+1],line[n+2],line[n+3],line[n+4]]\n",
    "                writer_out.writerow(update_line)\n",
    "        \n",
    "        f_in.close()\n",
    "        f_out.close()\n",
    "              \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    fix_turnstile_data(['turnstile-110528.txt', 'turnstile_110507.txt'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    '''\n",
    "    Write a function that takes the files in the list filenames, which all have the \n",
    "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
    "    them into one file located at output_file.  There should be ONE row with the column\n",
    "    headers, located at the top of the file. The input files do not have column header\n",
    "    rows of their own.\n",
    "    \n",
    "    For example, if file_1 has:\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    \n",
    "    and another file, file_2 has:\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    \n",
    "    We need to combine file_1 and file_2 into a master_file like below:\n",
    "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    '''\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            # your code here\n",
    "            f_in = open(filename, 'r')\n",
    "\n",
    "            for line in f_in:\n",
    "                master_file.write(line)\n",
    "            \n",
    "            f_in.close()\n",
    "            \n",
    "    master_file.close()\n",
    "                     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_master_turnstile_file(['updated_turnstile-110528.txt', 'updated_turnstile_110507.txt'], 'master_turnstile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C/A  UNIT       SCP     DATEn     TIMEn    DESCn ENTRIESn   EXITSn\n",
      "0     A002  R051  02-00-00  05-21-11  00:00:00  REGULAR  3169391  1097585\n",
      "1     A002  R051  02-00-00  05-21-11  04:00:00  REGULAR  3169415  1097588\n",
      "2     A002  R051  02-00-00  05-21-11  08:00:00  REGULAR  3169431  1097607\n",
      "3     A002  R051  02-00-00  05-21-11  12:00:00  REGULAR  3169506  1097686\n",
      "4     A002  R051  02-00-00  05-21-11  16:00:00  REGULAR  3169693  1097734\n",
      "5     A002  R051  02-00-00  05-21-11  20:00:00  REGULAR  3169998  1097769\n",
      "6     A002  R051  02-00-00  05-22-11  00:00:00  REGULAR  3170119  1097792\n",
      "7     A002  R051  02-00-00  05-22-11  04:00:00  REGULAR  3170146  1097801\n",
      "8     A002  R051  02-00-00  05-22-11  08:00:00  REGULAR  3170164  1097820\n",
      "9     A002  R051  02-00-00  05-22-11  12:00:00  REGULAR  3170240  1097867\n",
      "10    A002  R051  02-00-00  05-22-11  16:00:00  REGULAR  3170388  1097912\n",
      "11    A002  R051  02-00-00  05-22-11  20:00:00  REGULAR  3170611  1097941\n",
      "12    A002  R051  02-00-00  05-23-11  00:00:00  REGULAR  3170695  1097964\n",
      "13    A002  R051  02-00-00  05-23-11  04:00:00  REGULAR  3170701  1097964\n",
      "14    A002  R051  02-00-00  05-23-11  08:00:00  REGULAR  3170746  1098069\n",
      "15    A002  R051  02-00-00  05-23-11  12:00:00  REGULAR  3170897  1098378\n",
      "16    A002  R051  02-00-00  05-23-11  16:00:00  REGULAR  3171194  1098447\n",
      "17    A002  R051  02-00-00  05-23-11  20:00:00  REGULAR  3172059  1098511\n",
      "18    A002  R051  02-00-00  05-24-11  00:00:00  REGULAR  3172200  1098528\n",
      "19    A002  R051  02-00-00  05-24-11  04:00:00  REGULAR  3172214  1098529\n",
      "20    A002  R051  02-00-00  05-24-11  08:00:00  REGULAR  3172266  1098628\n",
      "21    A002  R051  02-00-00  05-24-11  12:00:00  REGULAR  3172407  1098952\n",
      "22    A002  R051  02-00-00  05-24-11  16:00:00  REGULAR  3172689  1099010\n",
      "23    A002  R051  02-00-00  05-24-11  20:00:00  REGULAR  3173590  1099055\n",
      "24    A002  R051  02-00-00  05-25-11  00:00:00  REGULAR  3173803  1099079\n",
      "25    A002  R051  02-00-00  05-25-11  04:00:00  REGULAR  3173826  1099081\n",
      "26    A002  R051  02-00-00  05-25-11  08:00:00  REGULAR  3173873  1099178\n",
      "27    A002  R051  02-00-00  05-25-11  12:00:00  REGULAR  3174022  1099496\n",
      "28    A002  R051  02-00-00  05-25-11  16:00:00  REGULAR  3174309  1099572\n",
      "29    A002  R051  02-00-00  05-25-11  20:00:00  REGULAR  3175172  1099651\n",
      "...    ...   ...       ...       ...       ...      ...      ...      ...\n",
      "6579  N030  R333  00-00-01  05-04-11  17:00:00  REGULAR  2990772  1702716\n",
      "6580  N030  R333  00-00-01  05-04-11  21:00:00  REGULAR  2990964  1702870\n",
      "6581  N030  R333  00-00-01  05-05-11  01:00:00  REGULAR  2991012  1702929\n",
      "6582  N030  R333  00-00-01  05-05-11  05:00:00  REGULAR  2991023  1702942\n",
      "6583  N030  R333  00-00-01  05-05-11  09:00:00  REGULAR  2991398  1703135\n",
      "6584  N030  R333  00-00-01  05-05-11  13:00:00  REGULAR  2991695  1703239\n",
      "6585  N030  R333  00-00-01  05-05-11  17:00:00  REGULAR  2991945  1703395\n",
      "6586  N030  R333  00-00-01  05-05-11  21:00:00  REGULAR  2992182  1703547\n",
      "6587  N030  R333  00-00-01  05-06-11  01:00:00  REGULAR  2992244  1703615\n",
      "6588  N030  R333  00-00-01  05-06-11  05:00:00  REGULAR  2992255  1703670\n",
      "6589  N030  R333  00-00-01  05-06-11  09:00:00  REGULAR  2992586  1703864\n",
      "6590  N030  R333  00-00-01  05-06-11  13:00:00  REGULAR  2992885  1703968\n",
      "6591  N030  R333  00-00-01  05-06-11  17:00:00  REGULAR  2993118  1704118\n",
      "6592  N030  R333  00-00-01  05-06-11  21:00:00  REGULAR  2993362  1704286\n",
      "6593  N030  R333  00-00-02  04-30-11  01:00:00  REGULAR  3205277   939833\n",
      "6594  N030  R333  00-00-02  04-30-11  05:00:00  REGULAR  3205304   939854\n",
      "6595  N030  R333  00-00-02  04-30-11  09:00:00  REGULAR  3205420   939876\n",
      "6596  N030  R333  00-00-02  04-30-11  13:00:00  REGULAR  3205694   939936\n",
      "6597  N030  R333  00-00-02  04-30-11  17:00:00  REGULAR  3205948   939988\n",
      "6598  N030  R333  00-00-02  04-30-11  21:00:00  REGULAR  3206133   940063\n",
      "6599  N030  R333  00-00-02  05-01-11  01:00:00  REGULAR  3206262   940128\n",
      "6600  N030  R333  00-00-02  05-01-11  05:00:00  REGULAR  3206281   940144\n",
      "6601  N030  R333  00-00-02  05-01-11  09:00:00  REGULAR  3206337   940161\n",
      "6602  N030  R333  00-00-02  05-01-11  13:00:00  REGULAR  3206588   940223\n",
      "6603  N030  R333  00-00-02  05-01-11  17:00:00  REGULAR  3206858   940279\n",
      "6604  N030  R333  00-00-02  05-01-11  21:00:00  REGULAR  3207005   940342\n",
      "6605  N030  R333  00-00-02  05-02-11  01:00:00  REGULAR  3207077   940372\n",
      "6606  N030  R333  00-00-02  05-02-11  05:00:00  REGULAR  3207106   940385\n",
      "6607  N030  R333  00-00-02  05-02-11  09:00:00  REGULAR  3207577   940489\n",
      "6608  N030  R333  00-00-02  05-02-11  13:00:00  REGULAR  3207932   940542\n",
      "\n",
      "[6609 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import csv\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    \n",
    "    For example, if the pandas dataframe is as follows:\n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "    \n",
    "    The dataframe will look like below after filtering to only rows where DESCn column\n",
    "    has the value 'REGULAR':\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    '''\n",
    "\n",
    "    turnstile_data = []\n",
    "    f_in = open(filename, 'r')\n",
    "    f_out1 = open('regular_turnstile.txt', 'w')\n",
    "    f_out2 = open('not_regular_turnstile.txt', 'w')\n",
    "\n",
    "    \n",
    "    reader_in = csv.reader(f_in, delimiter=',')\n",
    "    writer_out1 = csv.writer(f_out1, delimiter=',')\n",
    "    writer_out2 = csv.writer(f_out2, delimiter=',')\n",
    "     \n",
    "    for line in reader_in:\n",
    "        \n",
    "        if line[5] == 'REGULAR':\n",
    "#             line[6] = int(line[6].replace(\" \", \"\"))\n",
    "#             line[7] = int(line[7].replace(\" \", \"\"))\n",
    "            turnstile_data.append(line)\n",
    "            writer_out1.writerow(line)\n",
    "        else:\n",
    "             writer_out2.writerow(line)\n",
    "    \n",
    "    turnstile_data = pandas.DataFrame(turnstile_data,columns=['C/A','UNIT','SCP','DATEn','TIMEn','DESCn','ENTRIESn','EXITSn'])  \n",
    "    print(turnstile_data)\n",
    "    \n",
    "    f_in.close()\n",
    "    f_out1.close()\n",
    "    f_out2.close()\n",
    "    \n",
    "    return turnstile_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_by_regular('master_turnstile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative entry numbers to a count of entries since the last reading\n",
    "    (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called ENTRIESn_hourly\n",
    "       2) Assign to the column the difference between ENTRIESn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Examples of what your dataframe should look like at the end of this exercise:\n",
    "    \n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "       \n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
