{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rain days\n",
      "0         10\n"
     ]
    }
   ],
   "source": [
    "# Quiz 1\n",
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def num_rainy_days(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - a count of the number of days in the dataframe where\n",
    "    the rain column is equal to 1 (i.e., the number of days it\n",
    "    rained).  The dataframe will be titled 'weather_data'. You'll\n",
    "    need to provide the SQL query.  You might find SQL's count function\n",
    "    useful for this exercise.  You can read more about it here:\n",
    "    \n",
    "    https://dev.mysql.com/doc/refman/5.1/en/counting-rows.html\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select count(rain) as 'Rain Days' \n",
    "    from weather_data\n",
    "    where cast(rain as nteger)=1;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(num_rainy_days('weather-underground.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fog  max temperature\n",
      "0    0               86\n",
      "1    1               81\n"
     ]
    }
   ],
   "source": [
    "# Quiz 2\n",
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def max_temp_aggregate_by_fog(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return two columns and\n",
    "    two rows - whether it was foggy or not (0 or 1) and the max\n",
    "    maxtempi for that fog value (i.e., the maximum max temperature\n",
    "    for both foggy and non-foggy days).  The dataframe will be \n",
    "    titled 'weather_data'. You'll need to provide the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select fog, max(maxtempi) as 'Max Temperature'\n",
    "    from weather_data\n",
    "    group by fog;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(max_temp_aggregate_by_fog('weather-underground.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weekend temperature\n",
      "0            65.111111\n"
     ]
    }
   ],
   "source": [
    "# Quiz 3\n",
    "\n",
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - the average meantempi on days that are a Saturday\n",
    "    or Sunday (i.e., the the average mean temperature on weekends).\n",
    "    The dataframe will be titled 'weather_data' and you can access\n",
    "    the date in the dataframe via the 'date' column.\n",
    "    \n",
    "    You'll need to provide  the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    Also, you can convert dates to days of the week via the 'strftime' keyword in SQL.\n",
    "    For example, cast (strftime('%w', date) as integer) will return 0 if the date\n",
    "    is a Sunday or 6 if the date is a Saturday.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select avg(meantempi) as 'weekend Temperature'\n",
    "    from weather_data\n",
    "    where \n",
    "      cast (strftime('%w', date) as integer) = 0 or cast (strftime('%w', date) as integer) = 6;\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(avg_weekend_temperature('weather-underground.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(mintempi)\n",
      "0          61.25\n"
     ]
    }
   ],
   "source": [
    "# Quiz 4\n",
    "\n",
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def avg_min_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data. More specifically you want to find the average\n",
    "    minimum temperature (mintempi column of the weather dataframe) on \n",
    "    rainy days where the minimum temperature is greater than 55 degrees.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    select avg(mintempi)\n",
    "    from weather_data\n",
    "    where cast(rain as interger) = 1 and cast(mintempi as interger) > 55;\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(avg_min_temperature('weather-underground.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 5\n",
    "\n",
    "import csv\n",
    "\n",
    "def fix_turnstile_data(filenames):\n",
    "    '''\n",
    "    Filenames is a list of MTA Subway turnstile text files. A link to an example\n",
    "    MTA Subway turnstile text file can be seen at the URL below:\n",
    "    http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt\n",
    "    \n",
    "    As you can see, there are numerous data points included in each row of the\n",
    "    a MTA Subway turnstile text file. \n",
    "\n",
    "    You want to write a function that will update each row in the text\n",
    "    file so there is only one entry per row. A few examples below:\n",
    "    A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
    "    A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
    "    A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
    "    \n",
    "    Write the updates to a different text file in the format of \"updated_\" + filename.\n",
    "    For example:\n",
    "        1) if you read in a text file called \"turnstile_110521.txt\"\n",
    "        2) you should write the updated data to \"updated_turnstile_110521.txt\"\n",
    "\n",
    "    The order of the fields should be preserved. Remember to read through the \n",
    "    Instructor Notes below for more details on the task. \n",
    "    \n",
    "    In addition, here is a CSV reader/writer introductory tutorial:\n",
    "    http://goo.gl/HBbvyy\n",
    "    \n",
    "    You can see a sample of the turnstile text file that's passed into this function\n",
    "    and the the corresponding updated file by downloading these files from the resources:\n",
    "    \n",
    "    Sample input file: turnstile_110528.txt\n",
    "    Sample updated file: solution_turnstile_110528.txt\n",
    "    '''\n",
    "    for name in filenames:\n",
    "        # your code here\n",
    "        f_in = open(name, 'r')\n",
    "        f_out = open(\"updated_\" + name, 'w')\n",
    "\n",
    "        reader_in = csv.reader(f_in, delimiter=',')\n",
    "        writer_out = csv.writer(f_out, delimiter=',')\n",
    "        \n",
    "        for line in reader_in:\n",
    "            # print(len(line))\n",
    "            for n in range(3, len(line), 5):             \n",
    "                # formating the number and remove space\n",
    "                line[n+3] = int(line[n+3].replace(\" \", \"\"))\n",
    "                line[n+4] = int(line[n+4].replace(\" \", \"\"))\n",
    "                \n",
    "                update_line = [line[0],line[1],line[2],line[n],line[n+1],line[n+2],line[n+3],line[n+4]]\n",
    "                writer_out.writerow(update_line)\n",
    "        \n",
    "        f_in.close()\n",
    "        f_out.close()\n",
    "              \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    fix_turnstile_data(['turnstile-110528.txt', 'turnstile_110507.txt'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 6\n",
    "\n",
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    '''\n",
    "    Write a function that takes the files in the list filenames, which all have the \n",
    "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
    "    them into one file located at output_file.  There should be ONE row with the column\n",
    "    headers, located at the top of the file. The input files do not have column header\n",
    "    rows of their own.\n",
    "    \n",
    "    For example, if file_1 has:\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    \n",
    "    and another file, file_2 has:\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    \n",
    "    We need to combine file_1 and file_2 into a master_file like below:\n",
    "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    '''\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            # your code here\n",
    "            f_in = open(filename, 'r')\n",
    "\n",
    "            for line in f_in:\n",
    "                master_file.write(line)\n",
    "            \n",
    "            f_in.close()\n",
    "            \n",
    "    master_file.close()\n",
    "                     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_master_turnstile_file(['updated_turnstile-110528.txt', 'updated_turnstile_110507.txt'], 'master_turnstile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C/A  UNIT       SCP     DATEn     TIMEn    DESCn ENTRIESn   EXITSn\n",
      "0     A002  R051  02-00-00  05-21-11  00:00:00  REGULAR  3169391  1097585\n",
      "1     A002  R051  02-00-00  05-21-11  04:00:00  REGULAR  3169415  1097588\n",
      "2     A002  R051  02-00-00  05-21-11  08:00:00  REGULAR  3169431  1097607\n",
      "3     A002  R051  02-00-00  05-21-11  12:00:00  REGULAR  3169506  1097686\n",
      "4     A002  R051  02-00-00  05-21-11  16:00:00  REGULAR  3169693  1097734\n",
      "5     A002  R051  02-00-00  05-21-11  20:00:00  REGULAR  3169998  1097769\n",
      "6     A002  R051  02-00-00  05-22-11  00:00:00  REGULAR  3170119  1097792\n",
      "7     A002  R051  02-00-00  05-22-11  04:00:00  REGULAR  3170146  1097801\n",
      "8     A002  R051  02-00-00  05-22-11  08:00:00  REGULAR  3170164  1097820\n",
      "9     A002  R051  02-00-00  05-22-11  12:00:00  REGULAR  3170240  1097867\n",
      "10    A002  R051  02-00-00  05-22-11  16:00:00  REGULAR  3170388  1097912\n",
      "11    A002  R051  02-00-00  05-22-11  20:00:00  REGULAR  3170611  1097941\n",
      "12    A002  R051  02-00-00  05-23-11  00:00:00  REGULAR  3170695  1097964\n",
      "13    A002  R051  02-00-00  05-23-11  04:00:00  REGULAR  3170701  1097964\n",
      "14    A002  R051  02-00-00  05-23-11  08:00:00  REGULAR  3170746  1098069\n",
      "15    A002  R051  02-00-00  05-23-11  12:00:00  REGULAR  3170897  1098378\n",
      "16    A002  R051  02-00-00  05-23-11  16:00:00  REGULAR  3171194  1098447\n",
      "17    A002  R051  02-00-00  05-23-11  20:00:00  REGULAR  3172059  1098511\n",
      "18    A002  R051  02-00-00  05-24-11  00:00:00  REGULAR  3172200  1098528\n",
      "19    A002  R051  02-00-00  05-24-11  04:00:00  REGULAR  3172214  1098529\n",
      "20    A002  R051  02-00-00  05-24-11  08:00:00  REGULAR  3172266  1098628\n",
      "21    A002  R051  02-00-00  05-24-11  12:00:00  REGULAR  3172407  1098952\n",
      "22    A002  R051  02-00-00  05-24-11  16:00:00  REGULAR  3172689  1099010\n",
      "23    A002  R051  02-00-00  05-24-11  20:00:00  REGULAR  3173590  1099055\n",
      "24    A002  R051  02-00-00  05-25-11  00:00:00  REGULAR  3173803  1099079\n",
      "25    A002  R051  02-00-00  05-25-11  04:00:00  REGULAR  3173826  1099081\n",
      "26    A002  R051  02-00-00  05-25-11  08:00:00  REGULAR  3173873  1099178\n",
      "27    A002  R051  02-00-00  05-25-11  12:00:00  REGULAR  3174022  1099496\n",
      "28    A002  R051  02-00-00  05-25-11  16:00:00  REGULAR  3174309  1099572\n",
      "29    A002  R051  02-00-00  05-25-11  20:00:00  REGULAR  3175172  1099651\n",
      "...    ...   ...       ...       ...       ...      ...      ...      ...\n",
      "6579  N030  R333  00-00-01  05-04-11  17:00:00  REGULAR  2990772  1702716\n",
      "6580  N030  R333  00-00-01  05-04-11  21:00:00  REGULAR  2990964  1702870\n",
      "6581  N030  R333  00-00-01  05-05-11  01:00:00  REGULAR  2991012  1702929\n",
      "6582  N030  R333  00-00-01  05-05-11  05:00:00  REGULAR  2991023  1702942\n",
      "6583  N030  R333  00-00-01  05-05-11  09:00:00  REGULAR  2991398  1703135\n",
      "6584  N030  R333  00-00-01  05-05-11  13:00:00  REGULAR  2991695  1703239\n",
      "6585  N030  R333  00-00-01  05-05-11  17:00:00  REGULAR  2991945  1703395\n",
      "6586  N030  R333  00-00-01  05-05-11  21:00:00  REGULAR  2992182  1703547\n",
      "6587  N030  R333  00-00-01  05-06-11  01:00:00  REGULAR  2992244  1703615\n",
      "6588  N030  R333  00-00-01  05-06-11  05:00:00  REGULAR  2992255  1703670\n",
      "6589  N030  R333  00-00-01  05-06-11  09:00:00  REGULAR  2992586  1703864\n",
      "6590  N030  R333  00-00-01  05-06-11  13:00:00  REGULAR  2992885  1703968\n",
      "6591  N030  R333  00-00-01  05-06-11  17:00:00  REGULAR  2993118  1704118\n",
      "6592  N030  R333  00-00-01  05-06-11  21:00:00  REGULAR  2993362  1704286\n",
      "6593  N030  R333  00-00-02  04-30-11  01:00:00  REGULAR  3205277   939833\n",
      "6594  N030  R333  00-00-02  04-30-11  05:00:00  REGULAR  3205304   939854\n",
      "6595  N030  R333  00-00-02  04-30-11  09:00:00  REGULAR  3205420   939876\n",
      "6596  N030  R333  00-00-02  04-30-11  13:00:00  REGULAR  3205694   939936\n",
      "6597  N030  R333  00-00-02  04-30-11  17:00:00  REGULAR  3205948   939988\n",
      "6598  N030  R333  00-00-02  04-30-11  21:00:00  REGULAR  3206133   940063\n",
      "6599  N030  R333  00-00-02  05-01-11  01:00:00  REGULAR  3206262   940128\n",
      "6600  N030  R333  00-00-02  05-01-11  05:00:00  REGULAR  3206281   940144\n",
      "6601  N030  R333  00-00-02  05-01-11  09:00:00  REGULAR  3206337   940161\n",
      "6602  N030  R333  00-00-02  05-01-11  13:00:00  REGULAR  3206588   940223\n",
      "6603  N030  R333  00-00-02  05-01-11  17:00:00  REGULAR  3206858   940279\n",
      "6604  N030  R333  00-00-02  05-01-11  21:00:00  REGULAR  3207005   940342\n",
      "6605  N030  R333  00-00-02  05-02-11  01:00:00  REGULAR  3207077   940372\n",
      "6606  N030  R333  00-00-02  05-02-11  05:00:00  REGULAR  3207106   940385\n",
      "6607  N030  R333  00-00-02  05-02-11  09:00:00  REGULAR  3207577   940489\n",
      "6608  N030  R333  00-00-02  05-02-11  13:00:00  REGULAR  3207932   940542\n",
      "\n",
      "[6609 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quiz 7\n",
    "import pandas\n",
    "import csv\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    \n",
    "    For example, if the pandas dataframe is as follows:\n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "    \n",
    "    The dataframe will look like below after filtering to only rows where DESCn column\n",
    "    has the value 'REGULAR':\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    '''\n",
    "\n",
    "    turnstile_data = []\n",
    "    f_in = open(filename, 'r')\n",
    "    f_out1 = open('regular_turnstile.txt', 'w')\n",
    "    f_out2 = open('not_regular_turnstile.txt', 'w')\n",
    "\n",
    "    \n",
    "    reader_in = csv.reader(f_in, delimiter=',')\n",
    "    writer_out1 = csv.writer(f_out1, delimiter=',')\n",
    "    writer_out2 = csv.writer(f_out2, delimiter=',')\n",
    "     \n",
    "    for line in reader_in:\n",
    "        \n",
    "        if line[5] == 'REGULAR':\n",
    "#             line[6] = int(line[6].replace(\" \", \"\"))\n",
    "#             line[7] = int(line[7].replace(\" \", \"\"))\n",
    "            turnstile_data.append(line)\n",
    "            writer_out1.writerow(line)\n",
    "        else:\n",
    "             writer_out2.writerow(line)\n",
    "    \n",
    "    turnstile_data = pandas.DataFrame(turnstile_data,columns=['C/A','UNIT','SCP','DATEn','TIMEn','DESCn','ENTRIESn','EXITSn'])  \n",
    "    print(turnstile_data)\n",
    "    \n",
    "    f_in.close()\n",
    "    f_out1.close()\n",
    "    f_out2.close()\n",
    "    \n",
    "    return turnstile_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_by_regular('master_turnstile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn   EXITSn  \\\n",
      "0     A002  R051  02-00-00  05-21-11  00:00:00  REGULAR   3169391  1097585   \n",
      "1     A002  R051  02-00-00  05-21-11  04:00:00  REGULAR   3169415  1097588   \n",
      "2     A002  R051  02-00-00  05-21-11  08:00:00  REGULAR   3169431  1097607   \n",
      "3     A002  R051  02-00-00  05-21-11  12:00:00  REGULAR   3169506  1097686   \n",
      "4     A002  R051  02-00-00  05-21-11  16:00:00  REGULAR   3169693  1097734   \n",
      "5     A002  R051  02-00-00  05-21-11  20:00:00  REGULAR   3169998  1097769   \n",
      "6     A002  R051  02-00-00  05-22-11  00:00:00  REGULAR   3170119  1097792   \n",
      "7     A002  R051  02-00-00  05-22-11  04:00:00  REGULAR   3170146  1097801   \n",
      "8     A002  R051  02-00-00  05-22-11  08:00:00  REGULAR   3170164  1097820   \n",
      "9     A002  R051  02-00-00  05-22-11  12:00:00  REGULAR   3170240  1097867   \n",
      "10    A002  R051  02-00-00  05-22-11  16:00:00  REGULAR   3170388  1097912   \n",
      "11    A002  R051  02-00-00  05-22-11  20:00:00  REGULAR   3170611  1097941   \n",
      "12    A002  R051  02-00-00  05-23-11  00:00:00  REGULAR   3170695  1097964   \n",
      "13    A002  R051  02-00-00  05-23-11  04:00:00  REGULAR   3170701  1097964   \n",
      "14    A002  R051  02-00-00  05-23-11  08:00:00  REGULAR   3170746  1098069   \n",
      "15    A002  R051  02-00-00  05-23-11  12:00:00  REGULAR   3170897  1098378   \n",
      "16    A002  R051  02-00-00  05-23-11  16:00:00  REGULAR   3171194  1098447   \n",
      "17    A002  R051  02-00-00  05-23-11  20:00:00  REGULAR   3172059  1098511   \n",
      "18    A002  R051  02-00-00  05-24-11  00:00:00  REGULAR   3172200  1098528   \n",
      "19    A002  R051  02-00-00  05-24-11  04:00:00  REGULAR   3172214  1098529   \n",
      "20    A002  R051  02-00-00  05-24-11  08:00:00  REGULAR   3172266  1098628   \n",
      "21    A002  R051  02-00-00  05-24-11  12:00:00  REGULAR   3172407  1098952   \n",
      "22    A002  R051  02-00-00  05-24-11  16:00:00  REGULAR   3172689  1099010   \n",
      "23    A002  R051  02-00-00  05-24-11  20:00:00  REGULAR   3173590  1099055   \n",
      "24    A002  R051  02-00-00  05-25-11  00:00:00  REGULAR   3173803  1099079   \n",
      "25    A002  R051  02-00-00  05-25-11  04:00:00  REGULAR   3173826  1099081   \n",
      "26    A002  R051  02-00-00  05-25-11  08:00:00  REGULAR   3173873  1099178   \n",
      "27    A002  R051  02-00-00  05-25-11  12:00:00  REGULAR   3174022  1099496   \n",
      "28    A002  R051  02-00-00  05-25-11  16:00:00  REGULAR   3174309  1099572   \n",
      "29    A002  R051  02-00-00  05-25-11  20:00:00  REGULAR   3175172  1099651   \n",
      "...    ...   ...       ...       ...       ...      ...       ...      ...   \n",
      "6579  N030  R333  00-00-01  05-04-11  17:00:00  REGULAR   2990772  1702716   \n",
      "6580  N030  R333  00-00-01  05-04-11  21:00:00  REGULAR   2990964  1702870   \n",
      "6581  N030  R333  00-00-01  05-05-11  01:00:00  REGULAR   2991012  1702929   \n",
      "6582  N030  R333  00-00-01  05-05-11  05:00:00  REGULAR   2991023  1702942   \n",
      "6583  N030  R333  00-00-01  05-05-11  09:00:00  REGULAR   2991398  1703135   \n",
      "6584  N030  R333  00-00-01  05-05-11  13:00:00  REGULAR   2991695  1703239   \n",
      "6585  N030  R333  00-00-01  05-05-11  17:00:00  REGULAR   2991945  1703395   \n",
      "6586  N030  R333  00-00-01  05-05-11  21:00:00  REGULAR   2992182  1703547   \n",
      "6587  N030  R333  00-00-01  05-06-11  01:00:00  REGULAR   2992244  1703615   \n",
      "6588  N030  R333  00-00-01  05-06-11  05:00:00  REGULAR   2992255  1703670   \n",
      "6589  N030  R333  00-00-01  05-06-11  09:00:00  REGULAR   2992586  1703864   \n",
      "6590  N030  R333  00-00-01  05-06-11  13:00:00  REGULAR   2992885  1703968   \n",
      "6591  N030  R333  00-00-01  05-06-11  17:00:00  REGULAR   2993118  1704118   \n",
      "6592  N030  R333  00-00-01  05-06-11  21:00:00  REGULAR   2993362  1704286   \n",
      "6593  N030  R333  00-00-02  04-30-11  01:00:00  REGULAR   3205277   939833   \n",
      "6594  N030  R333  00-00-02  04-30-11  05:00:00  REGULAR   3205304   939854   \n",
      "6595  N030  R333  00-00-02  04-30-11  09:00:00  REGULAR   3205420   939876   \n",
      "6596  N030  R333  00-00-02  04-30-11  13:00:00  REGULAR   3205694   939936   \n",
      "6597  N030  R333  00-00-02  04-30-11  17:00:00  REGULAR   3205948   939988   \n",
      "6598  N030  R333  00-00-02  04-30-11  21:00:00  REGULAR   3206133   940063   \n",
      "6599  N030  R333  00-00-02  05-01-11  01:00:00  REGULAR   3206262   940128   \n",
      "6600  N030  R333  00-00-02  05-01-11  05:00:00  REGULAR   3206281   940144   \n",
      "6601  N030  R333  00-00-02  05-01-11  09:00:00  REGULAR   3206337   940161   \n",
      "6602  N030  R333  00-00-02  05-01-11  13:00:00  REGULAR   3206588   940223   \n",
      "6603  N030  R333  00-00-02  05-01-11  17:00:00  REGULAR   3206858   940279   \n",
      "6604  N030  R333  00-00-02  05-01-11  21:00:00  REGULAR   3207005   940342   \n",
      "6605  N030  R333  00-00-02  05-02-11  01:00:00  REGULAR   3207077   940372   \n",
      "6606  N030  R333  00-00-02  05-02-11  05:00:00  REGULAR   3207106   940385   \n",
      "6607  N030  R333  00-00-02  05-02-11  09:00:00  REGULAR   3207577   940489   \n",
      "6608  N030  R333  00-00-02  05-02-11  13:00:00  REGULAR   3207932   940542   \n",
      "\n",
      "      ENTRIESn_hourly  \n",
      "0                 1.0  \n",
      "1                24.0  \n",
      "2                16.0  \n",
      "3                75.0  \n",
      "4               187.0  \n",
      "5               305.0  \n",
      "6               121.0  \n",
      "7                27.0  \n",
      "8                18.0  \n",
      "9                76.0  \n",
      "10              148.0  \n",
      "11              223.0  \n",
      "12               84.0  \n",
      "13                6.0  \n",
      "14               45.0  \n",
      "15              151.0  \n",
      "16              297.0  \n",
      "17              865.0  \n",
      "18              141.0  \n",
      "19               14.0  \n",
      "20               52.0  \n",
      "21              141.0  \n",
      "22              282.0  \n",
      "23              901.0  \n",
      "24              213.0  \n",
      "25               23.0  \n",
      "26               47.0  \n",
      "27              149.0  \n",
      "28              287.0  \n",
      "29              863.0  \n",
      "...               ...  \n",
      "6579            213.0  \n",
      "6580            192.0  \n",
      "6581             48.0  \n",
      "6582             11.0  \n",
      "6583            375.0  \n",
      "6584            297.0  \n",
      "6585            250.0  \n",
      "6586            237.0  \n",
      "6587             62.0  \n",
      "6588             11.0  \n",
      "6589            331.0  \n",
      "6590            299.0  \n",
      "6591            233.0  \n",
      "6592            244.0  \n",
      "6593              1.0  \n",
      "6594             27.0  \n",
      "6595            116.0  \n",
      "6596            274.0  \n",
      "6597            254.0  \n",
      "6598            185.0  \n",
      "6599            129.0  \n",
      "6600             19.0  \n",
      "6601             56.0  \n",
      "6602            251.0  \n",
      "6603            270.0  \n",
      "6604            147.0  \n",
      "6605             72.0  \n",
      "6606             29.0  \n",
      "6607            471.0  \n",
      "6608            355.0  \n",
      "\n",
      "[6609 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quiz 8\n",
    "import pandas as pd\n",
    "from numpy import nan as NA\n",
    "import csv\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative entry numbers to a count of entries since the last reading\n",
    "    (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called ENTRIESn_hourly\n",
    "       2) Assign to the column the difference between ENTRIESn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Examples of what your dataframe should look like at the end of this exercise:\n",
    "    \n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(list(df), columns=['C/A','UNIT','SCP','DATEn','TIMEn','DESCn','ENTRIESn','EXITSn'])\n",
    "    df['ENTRIESn'] = df['ENTRIESn'].astype(int)\n",
    "    df['EXITSn'] = df['EXITSn'].astype(int)\n",
    "    newdf = df.shift(1).fillna(1)\n",
    "    \n",
    "    result = df['ENTRIESn'] - newdf['ENTRIESn']\n",
    "    \n",
    "#     df['ENTRIESn_hourly'].fillna(value=1, axis=0, inplace=True)\n",
    "    \n",
    "      \n",
    "    for i in range(len(result)):\n",
    "        if result[i] > 3000 or result[i] < 0:\n",
    "            result[i] = 1\n",
    "    \n",
    "    df['ENTRIESn_hourly'] = result\n",
    "    print(df)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    f_in = open('regular_turnstile.txt', 'r')\n",
    "    reader_in = csv.reader(f_in, delimiter=',')\n",
    "    get_hourly_entries(reader_in).to_csv('records_turnstile.txt', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C/A  UNIT       SCP     DATEn     TIMEn    DESCn ENTRIESn   EXITSn  \\\n",
      "0     A002  R051  02-00-00  05-21-11  00:00:00  REGULAR  3169391  1097585   \n",
      "1     A002  R051  02-00-00  05-21-11  04:00:00  REGULAR  3169415  1097588   \n",
      "2     A002  R051  02-00-00  05-21-11  08:00:00  REGULAR  3169431  1097607   \n",
      "3     A002  R051  02-00-00  05-21-11  12:00:00  REGULAR  3169506  1097686   \n",
      "4     A002  R051  02-00-00  05-21-11  16:00:00  REGULAR  3169693  1097734   \n",
      "5     A002  R051  02-00-00  05-21-11  20:00:00  REGULAR  3169998  1097769   \n",
      "6     A002  R051  02-00-00  05-22-11  00:00:00  REGULAR  3170119  1097792   \n",
      "7     A002  R051  02-00-00  05-22-11  04:00:00  REGULAR  3170146  1097801   \n",
      "8     A002  R051  02-00-00  05-22-11  08:00:00  REGULAR  3170164  1097820   \n",
      "9     A002  R051  02-00-00  05-22-11  12:00:00  REGULAR  3170240  1097867   \n",
      "10    A002  R051  02-00-00  05-22-11  16:00:00  REGULAR  3170388  1097912   \n",
      "11    A002  R051  02-00-00  05-22-11  20:00:00  REGULAR  3170611  1097941   \n",
      "12    A002  R051  02-00-00  05-23-11  00:00:00  REGULAR  3170695  1097964   \n",
      "13    A002  R051  02-00-00  05-23-11  04:00:00  REGULAR  3170701  1097964   \n",
      "14    A002  R051  02-00-00  05-23-11  08:00:00  REGULAR  3170746  1098069   \n",
      "15    A002  R051  02-00-00  05-23-11  12:00:00  REGULAR  3170897  1098378   \n",
      "16    A002  R051  02-00-00  05-23-11  16:00:00  REGULAR  3171194  1098447   \n",
      "17    A002  R051  02-00-00  05-23-11  20:00:00  REGULAR  3172059  1098511   \n",
      "18    A002  R051  02-00-00  05-24-11  00:00:00  REGULAR  3172200  1098528   \n",
      "19    A002  R051  02-00-00  05-24-11  04:00:00  REGULAR  3172214  1098529   \n",
      "20    A002  R051  02-00-00  05-24-11  08:00:00  REGULAR  3172266  1098628   \n",
      "21    A002  R051  02-00-00  05-24-11  12:00:00  REGULAR  3172407  1098952   \n",
      "22    A002  R051  02-00-00  05-24-11  16:00:00  REGULAR  3172689  1099010   \n",
      "23    A002  R051  02-00-00  05-24-11  20:00:00  REGULAR  3173590  1099055   \n",
      "24    A002  R051  02-00-00  05-25-11  00:00:00  REGULAR  3173803  1099079   \n",
      "25    A002  R051  02-00-00  05-25-11  04:00:00  REGULAR  3173826  1099081   \n",
      "26    A002  R051  02-00-00  05-25-11  08:00:00  REGULAR  3173873  1099178   \n",
      "27    A002  R051  02-00-00  05-25-11  12:00:00  REGULAR  3174022  1099496   \n",
      "28    A002  R051  02-00-00  05-25-11  16:00:00  REGULAR  3174309  1099572   \n",
      "29    A002  R051  02-00-00  05-25-11  20:00:00  REGULAR  3175172  1099651   \n",
      "...    ...   ...       ...       ...       ...      ...      ...      ...   \n",
      "6579  N030  R333  00-00-01  05-04-11  17:00:00  REGULAR  2990772  1702716   \n",
      "6580  N030  R333  00-00-01  05-04-11  21:00:00  REGULAR  2990964  1702870   \n",
      "6581  N030  R333  00-00-01  05-05-11  01:00:00  REGULAR  2991012  1702929   \n",
      "6582  N030  R333  00-00-01  05-05-11  05:00:00  REGULAR  2991023  1702942   \n",
      "6583  N030  R333  00-00-01  05-05-11  09:00:00  REGULAR  2991398  1703135   \n",
      "6584  N030  R333  00-00-01  05-05-11  13:00:00  REGULAR  2991695  1703239   \n",
      "6585  N030  R333  00-00-01  05-05-11  17:00:00  REGULAR  2991945  1703395   \n",
      "6586  N030  R333  00-00-01  05-05-11  21:00:00  REGULAR  2992182  1703547   \n",
      "6587  N030  R333  00-00-01  05-06-11  01:00:00  REGULAR  2992244  1703615   \n",
      "6588  N030  R333  00-00-01  05-06-11  05:00:00  REGULAR  2992255  1703670   \n",
      "6589  N030  R333  00-00-01  05-06-11  09:00:00  REGULAR  2992586  1703864   \n",
      "6590  N030  R333  00-00-01  05-06-11  13:00:00  REGULAR  2992885  1703968   \n",
      "6591  N030  R333  00-00-01  05-06-11  17:00:00  REGULAR  2993118  1704118   \n",
      "6592  N030  R333  00-00-01  05-06-11  21:00:00  REGULAR  2993362  1704286   \n",
      "6593  N030  R333  00-00-02  04-30-11  01:00:00  REGULAR  3205277   939833   \n",
      "6594  N030  R333  00-00-02  04-30-11  05:00:00  REGULAR  3205304   939854   \n",
      "6595  N030  R333  00-00-02  04-30-11  09:00:00  REGULAR  3205420   939876   \n",
      "6596  N030  R333  00-00-02  04-30-11  13:00:00  REGULAR  3205694   939936   \n",
      "6597  N030  R333  00-00-02  04-30-11  17:00:00  REGULAR  3205948   939988   \n",
      "6598  N030  R333  00-00-02  04-30-11  21:00:00  REGULAR  3206133   940063   \n",
      "6599  N030  R333  00-00-02  05-01-11  01:00:00  REGULAR  3206262   940128   \n",
      "6600  N030  R333  00-00-02  05-01-11  05:00:00  REGULAR  3206281   940144   \n",
      "6601  N030  R333  00-00-02  05-01-11  09:00:00  REGULAR  3206337   940161   \n",
      "6602  N030  R333  00-00-02  05-01-11  13:00:00  REGULAR  3206588   940223   \n",
      "6603  N030  R333  00-00-02  05-01-11  17:00:00  REGULAR  3206858   940279   \n",
      "6604  N030  R333  00-00-02  05-01-11  21:00:00  REGULAR  3207005   940342   \n",
      "6605  N030  R333  00-00-02  05-02-11  01:00:00  REGULAR  3207077   940372   \n",
      "6606  N030  R333  00-00-02  05-02-11  05:00:00  REGULAR  3207106   940385   \n",
      "6607  N030  R333  00-00-02  05-02-11  09:00:00  REGULAR  3207577   940489   \n",
      "6608  N030  R333  00-00-02  05-02-11  13:00:00  REGULAR  3207932   940542   \n",
      "\n",
      "     ENTRIESn_hourly  EXITSn_hourly  \n",
      "0                1.0            1.0  \n",
      "1               24.0            3.0  \n",
      "2               16.0           19.0  \n",
      "3               75.0           79.0  \n",
      "4              187.0           48.0  \n",
      "5              305.0           35.0  \n",
      "6              121.0           23.0  \n",
      "7               27.0            9.0  \n",
      "8               18.0           19.0  \n",
      "9               76.0           47.0  \n",
      "10             148.0           45.0  \n",
      "11             223.0           29.0  \n",
      "12              84.0           23.0  \n",
      "13               6.0            0.0  \n",
      "14              45.0          105.0  \n",
      "15             151.0          309.0  \n",
      "16             297.0           69.0  \n",
      "17             865.0           64.0  \n",
      "18             141.0           17.0  \n",
      "19              14.0            1.0  \n",
      "20              52.0           99.0  \n",
      "21             141.0          324.0  \n",
      "22             282.0           58.0  \n",
      "23             901.0           45.0  \n",
      "24             213.0           24.0  \n",
      "25              23.0            2.0  \n",
      "26              47.0           97.0  \n",
      "27             149.0          318.0  \n",
      "28             287.0           76.0  \n",
      "29             863.0           79.0  \n",
      "...              ...            ...  \n",
      "6579           213.0          153.0  \n",
      "6580           192.0          154.0  \n",
      "6581            48.0           59.0  \n",
      "6582            11.0           13.0  \n",
      "6583           375.0          193.0  \n",
      "6584           297.0          104.0  \n",
      "6585           250.0          156.0  \n",
      "6586           237.0          152.0  \n",
      "6587            62.0           68.0  \n",
      "6588            11.0           55.0  \n",
      "6589           331.0          194.0  \n",
      "6590           299.0          104.0  \n",
      "6591           233.0          150.0  \n",
      "6592           244.0          168.0  \n",
      "6593             1.0      -764453.0  \n",
      "6594            27.0           21.0  \n",
      "6595           116.0           22.0  \n",
      "6596           274.0           60.0  \n",
      "6597           254.0           52.0  \n",
      "6598           185.0           75.0  \n",
      "6599           129.0           65.0  \n",
      "6600            19.0           16.0  \n",
      "6601            56.0           17.0  \n",
      "6602           251.0           62.0  \n",
      "6603           270.0           56.0  \n",
      "6604           147.0           63.0  \n",
      "6605            72.0           30.0  \n",
      "6606            29.0           13.0  \n",
      "6607           471.0          104.0  \n",
      "6608           355.0           53.0  \n",
      "\n",
      "[6609 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quiz 9\n",
    "import pandas as pd\n",
    "\n",
    "def get_hourly_exits(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative exit numbers to a count of exits since the last reading\n",
    "    (i.e., exits since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called EXITSn_hourly\n",
    "       2) Assign to the column the difference between EXITSn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 0.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Example dataframe below:\n",
    "\n",
    "          Unnamed: 0   C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly  EXITSn_hourly\n",
    "    0              0  A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                0              0\n",
    "    1              1  A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23              8\n",
    "    2              2  A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18             18\n",
    "    3              3  A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71             54\n",
    "    4              4  A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170             44\n",
    "    5              5  A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214             42\n",
    "    6              6  A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87             11\n",
    "    7              7  A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10              3\n",
    "    8              8  A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36             89\n",
    "    9              9  A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153            333\n",
    "    '''\n",
    "    \n",
    "    #your code here\n",
    "    df = pd.DataFrame(list(df),columns=['C/A','UNIT','SCP','DATEn','TIMEn','DESCn','ENTRIESn','EXITSn','ENTRIESn_hourly'])\n",
    "    \n",
    "    df['EXITSn'] = df['EXITSn'].astype(int)\n",
    "    \n",
    "    dfshift = df.shift(periods=1)\n",
    "    \n",
    "    df['EXITSn_hourly'] = df['EXITSn'] - dfshift['EXITSn']\n",
    "    \n",
    "    df[\"EXITSn_hourly\"].fillna(value=0,axis=0,inplace=True) # No use in my env\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    f_in = open('records_turnstile.txt', 'r')\n",
    "    reader_in = csv.reader(f_in, delimiter=',')\n",
    "    get_hourly_exits(reader_in).to_csv('records_turnstile1.txt',index=False, header=False)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:57:02\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Quiz 10\n",
    "import pandas\n",
    "import datetime as datetime\n",
    "\n",
    "def time_to_hour(time):\n",
    "    '''\n",
    "    Given an input variable time that represents time in the format of:\n",
    "    \"00:00:00\" (hour:minutes:seconds)\n",
    "    \n",
    "    Write a function to extract the hour part from the input variable time\n",
    "    and return it as an integer. For example:\n",
    "        1) if hour is 00, your code should return 0\n",
    "        2) if hour is 01, your code should return 1\n",
    "        3) if hour is 21, your code should return 21\n",
    "        \n",
    "    Please return hour as an integer.\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    hour = int(time[0:2])\n",
    "    print(hour)\n",
    "    \n",
    "    return hour\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    time = str(datetime.datetime.now().strftime('%H:%M:%S'))\n",
    "    print(time)\n",
    "    time_to_hour(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-12-18\n",
      "2018-08-12\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Quiz 11\n",
    "\n",
    "import datetime\n",
    "\n",
    "def reformat_subway_dates(date):\n",
    "    '''\n",
    "    The dates in our subway data are formatted in the format month-day-year.\n",
    "    The dates in our weather underground data are formatted year-month-day.\n",
    "    \n",
    "    In order to join these two data sets together, we'll want the dates formatted\n",
    "    the same way.  Write a function that takes as its input a date in the MTA Subway\n",
    "    data format, and returns a date in the weather underground format.\n",
    "    \n",
    "    Hint: \n",
    "    There are a couple of useful functions in the datetime library that will\n",
    "    help on this assignment, called strptime and strftime. \n",
    "    More info can be seen here and further in the documentation section:\n",
    "    http://docs.python.org/2/library/datetime.html#datetime.datetime.strptime\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    date_formatted = datetime.datetime.strptime(date,'%m-%d-%y').strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(date_formatted)\n",
    "    print(type(date_formatted))\n",
    "    \n",
    "    return date_formatted\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    date = str(datetime.datetime.now().strftime('%m-%d-%y'))\n",
    "    print(date)\n",
    "    reformat_subway_dates(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
